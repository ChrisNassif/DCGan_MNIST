{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO give the discriminator more time to train as described in the descriminator advantage global variable\n",
    "# TODO make the generator connect up to a FC layer after convolutional upscaling\n",
    "# TODO https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/78\n",
    "\n",
    "import torch\n",
    "import torch.utils.data.dataloader\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "DISCRIMINATOR_ADVANTAGE = 1\n",
    "# GENERATOR_ADVANTAGE = 1\n",
    "DISCRIMINATOR_LEARNING_RATE = 0.0005\n",
    "GENERATOR_LEARNING_RATE = 0.001\n",
    "LATENT_SPACE_SIZE = 100\n",
    "IMAGE_SIZE = 28\n",
    "CHANNEL_COUNT = 1\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "REAL_DATA_LABEL = 0\n",
    "GENERATED_DATA_LABEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_channel_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "one_channel_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "BATCH_SIZE = 15\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=one_channel_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=one_channel_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def generate_hidden_layer(self, input_channels, output_channels, output_up_scaling_factor, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_channels, output_channels, output_up_scaling_factor, 1, padding),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(LATENT_SPACE_SIZE, 400),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # self.layer2 = self.generate_hidden_layer(400, 200, 4, 0)    # 4x4 \n",
    "        self.layer2 = self.generate_hidden_layer(LATENT_SPACE_SIZE, 100, 4, 0)    # 4x4 \n",
    "        self.layer3 = self.generate_hidden_layer(100, 50, 5, 0)   # 8x8\n",
    "        self.layer4 = self.generate_hidden_layer(50, 25, 9, 0)    # 16x16\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(25, CHANNEL_COUNT, 13, 1, 0),  # 28x28\n",
    "            nn.BatchNorm2d(CHANNEL_COUNT),\n",
    "            # nn.LeakyReLU()\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.tensor): Some 1d tensor that consists of pure gaussian noise\n",
    "        \"\"\"\n",
    "        # print(x.size())\n",
    "        # x = self.layer1(x)\n",
    "        # print(x.size())\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class Discriminator(nn.Module):\n",
    "    def generate_convolutional_layer(self, in_channels, out_channels, convolution_kernel_size, pooling_kernel_size, stride):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, convolution_kernel_size, stride, padding=1),\n",
    "            nn.AvgPool2d(pooling_kernel_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.convolutional_layer1 = self.generate_convolutional_layer(CHANNEL_COUNT, 10, 3, 2, 1)\n",
    "        self.convolutional_layer2 = self.generate_convolutional_layer(10, 30, 3, 2, 1) \n",
    "        self.convolutional_layer3 = self.generate_convolutional_layer(20, 40, 3, 2, 1)\n",
    "        self.fully_connected1 = nn.Sequential(\n",
    "            nn.LazyLinear(128),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.fully_connected2 = nn.Sequential(\n",
    "            nn.LazyLinear(86),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.fully_connected3 = nn.Sequential(\n",
    "            nn.LazyLinear(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.tensor): Tensor that represents a 3x32x32 image\n",
    "        \"\"\"\n",
    "        # print(x.size())\n",
    "        x = self.convolutional_layer1(x)\n",
    "        x = self.convolutional_layer2(x)\n",
    "        # x = self.convolutional_layer3(x)\n",
    "        x = x.view(x.size(0), -1)     # flatten each of the tensors in the batch so that we can feed it into the fully connected layer\n",
    "        x = self.fully_connected1(x)\n",
    "        # x = self.fully_connected2(x)\n",
    "        return self.fully_connected3(x)\n",
    "        # return x.view(-1)   # one other flatten to make sure everything lines up correctly\n",
    "\n",
    "    \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "\n",
    "# generator = Generator()\n",
    "# generator.apply(weights_init)\n",
    "# generator.to(DEVICE)\n",
    "generator = Generator().to(DEVICE)\n",
    "generator.load_state_dict(torch.load(\"models/generator_MNIST\"))\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), GENERATOR_LEARNING_RATE/ DISCRIMINATOR_ADVANTAGE)\n",
    "torch.nn.utils.clip_grad_norm_(generator.parameters(), 1)\n",
    "\n",
    "# discriminator = Discriminator()\n",
    "# discriminator.apply(weights_init)\n",
    "# discriminator.to(DEVICE)\n",
    "discriminator = Discriminator().to(DEVICE)\n",
    "discriminator.load_state_dict(torch.load(\"models/discriminator_MNIST\"))\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), DISCRIMINATOR_LEARNING_RATE)\n",
    "torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 1)\n",
    "\n",
    "# loss_function = nn.MSELoss()\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_noise(batch_size, dimensions):\n",
    "    return torch.randn(batch_size, dimensions, 1, 1, device=DEVICE)\n",
    "\n",
    "\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "\n",
    "cur_training_iteration = 0\n",
    "\n",
    "# print(trainloader.__iter__()._next_data())\n",
    "for epoch_index in range(NUM_EPOCHS):\n",
    "    for index, (real_images, image_labels) in enumerate(tqdm(trainloader, desc=f\"epoch {epoch_index}\")):\n",
    "        \n",
    "        real_images = real_images.to(DEVICE)\n",
    "        image_labels = image_labels.float().to(DEVICE)\n",
    "    \n",
    "        labels = torch.zeros((real_images.size(0), 1), device=DEVICE).cuda()\n",
    "        \n",
    "        discriminator_optimizer.zero_grad()\n",
    "        #\n",
    "        # Train the discriminator network\n",
    "        #\n",
    "        # real data\n",
    "        labels.fill_(REAL_DATA_LABEL)\n",
    "        discriminator_loss_real = loss_function(discriminator(real_images), labels)\n",
    "        discriminator_loss_real.backward() \n",
    "\n",
    "        # fake data\n",
    "        labels.fill_(GENERATED_DATA_LABEL)\n",
    "        generated_images = generator(generate_gaussian_noise(BATCH_SIZE, LATENT_SPACE_SIZE))\n",
    "        discriminator_loss_generated = loss_function(discriminator(generated_images), labels)\n",
    "        discriminator_loss_generated.backward(retain_graph=True)\n",
    "        \n",
    "        discriminator_losses.append(discriminator_loss_real.item() + discriminator_loss_generated.item())\n",
    "        # print(discriminator_losses[-1])\n",
    "        \n",
    "        discriminator_optimizer.step()\n",
    "            \n",
    "        #\n",
    "        # Train the generator network\n",
    "        #\n",
    "        labels.fill_(REAL_DATA_LABEL)\n",
    "        generator_loss = loss_function(discriminator(generated_images), labels)\n",
    "        generator_loss.backward()\n",
    "        generator_losses.append(generator_loss.item())\n",
    "        \n",
    "        # print(generator_loss.item())\n",
    "        # print()\n",
    "        \n",
    "        if cur_training_iteration % DISCRIMINATOR_ADVANTAGE == 0:\n",
    "            generator_optimizer.step()\n",
    "            generator_optimizer.zero_grad()\n",
    "        \n",
    "        cur_training_iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import moveaxis\n",
    "plt.plot(discriminator_losses)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(generator_losses)\n",
    "plt.show()\n",
    "\n",
    "test_images = generator(generate_gaussian_noise(BATCH_SIZE, LATENT_SPACE_SIZE))\n",
    "# print(test_images)\n",
    "test_images = (-255 * ((test_images + 1)/ 2)).cpu().detach().numpy().astype(int)\n",
    "\n",
    "test_image = moveaxis(test_images[1], 0, 2)\n",
    "print(test_image.astype(int))\n",
    "plt.imshow(test_image.astype(int), cmap=\"gray\")\n",
    "# x = torchvision.utils.make_grid(torch.tensor(images))\n",
    "# print(x.size())\n",
    "# plt.imshow(x)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"models/generator_MNIST2\")\n",
    "torch.save(discriminator.state_dict(), \"models/discriminator_MNIST2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
